```insta-toc
---
title:
  name: Table of Contents
  level: 1
  center: false
exclude: ""
style:
  listType: dash
omit: []
levels:
  min: 1
  max: 6
---

# Table of Contents

- 01. 背景
- 02. 产品拆解
- 03. AI 时代开发的一些经验阶段性汇总
    - 怎样才能高速开发一款软件
    - AI IDE 的一些个人使用技巧
    - LLM 开发的一些经验
    - 后端开发的一些经验
    - 前端开发的一些经验
- 04. DeepSeek：基于 OCR 数据还原聊天记录的推理全过程（精彩）
```



![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300807764.png)

## **01.** 背景

简单记录一下从昨天到今天凌晨大致完成的微信回复助手，体验网址在： https://you-reply.cs-magic.cn （免费，燃烧我自己的 token，各位兄弟姐妹们友情给我打赏点即可）。

写这个产品主要是年前就想做一款群发拜年的产品，但一直有其他事情就搁置了，无奈大家过年实在过于热情，就顺手花了一天时间写了一款回复拜年的产品，顺带检测一下 DeepSeek 的水平。特别感谢 #公众号：AI产品黄叔 在 DeepSeek API 平台宕机的恶劣环境下也能给我一枚尊贵的 DEEPSEEK_API_KEY，这才能让我顺利地“一天内”完成本项目。

之所以这个项目我必须要 DeepSeek，是因为其他模型（除了 o1-pro）说出的话实在太车轱辘了，根本达不到真人可用的级别。

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300752274.png)

但这种尴尬，DeepSeek 的推理模型直接秒破了。

我和朋友前两天简单聊了聊梁，还对比了黄铮、马斯克等，我总结说梁可能结合了中西的优点：
- 极致的低调务实
- 极致的技术主义

朋友说：「就是优秀的我不太敢相信」。

是的。坦白说，我到现在都还没有缓过神来，因为我去年标榜的「更像真人的 AI 社交助理」的理想，在 DeepSeek 这里几乎就成了一个笑话……

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300806143.png)

我觉得一丝丝沮丧确实是有的，这种沮丧来自于个人微小的步伐实在跑不过时代的巨浪，总有被一下拍死在沙滩上的疑虑。

但更多地还是兴奋，一种游舞在浪潮之巅上的兴奋，因为像 DeepSeek 这样的底层技术越是强大，我们中上层的应用开发者能做的事情就越多，效率越高、质量越高、人效比也越高。

从这个角度，我是必须感谢时代的。即便这个时代可能并没有我的一份，能看到如此惊涛骇浪，也是无悔矣。

Anyway，从今年开始，中美的科技态势攻守易型了，AI 与人类的差异也攻守易型了，我们，要做好心理与行动上的准备。

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300819760.png)

## **02.** 产品拆解

这两年看了不少应用层产品，总体来看，除了少数产品确实有一些算法、技术壁垒之外，其他的大多还是靠某个创始人的独特魅力、产品品味与市场洞察，获得一定的资金（有，但不多，例如奇绩的30 万刀、红杉的200 万刀），然后招人、做产品、推市场。

我们这个产品，属于私域营销领域，再准确点，就是精准营销，一般不但要做到高质量地回复，还要能做到高质量地自动化回复，以及主动发起，涉及到一整套 RPA 私域营销的技术，相对比较较重，主要重的成本在维护 RPA 的稳定性、确保 RPA 的合规性以及调试 RAG 方案的效果。

但过年嘛，所以，先做个能直接让大家玩起来的：
1. 截图
2. 识别
3. 回复

我是先做了回复功能，一开始用的是 Claude，效果不好，后面换上了 DeepSeek，打开推理模型，确实一下子就好很多了。

而且换 DeepSeek 后，连 prompt 都几乎不用了，不用去限定各种风格、代入啥的，它自己都懂，所以我最后的 prompt 就仅仅是：

```markdown
这是一段微信聊天记录上下文：

<context>

${parsedText}

</context>

场景是：

<background>

${background}

</background>

用户聊天风格：

<style>

${style}

</style>

请代替真人回复，要求：

- 分辨不出是否 AI 生成

- 要遵循用户的聊天风格（若有）

- 直接输出结果（无需解释），以方便用户直接复制粘贴
```

除了一些参数传入之外，其他的基本朴素无华，而我朋友用 claude 给我发来的 prompt 是：

```markdown
# 新春送福小助手
你是一位暖心的新春祝福小助手，精通中国传统文化，特别擅长把新年祝福说得暖暖的、有趣又应景！
## 基本设定
- 你是一个懂得中国传统文化，但说话方式很接地气的拜年小助手
- 你特别了解微信等社交软件的日常交流方式，知道怎么聊天既不会太随意也不会太正式
- 你会根据关系远近调整语气，但都保持轻松自然的社交感
- 你懂得2024蛇年的各种吉祥寓意，能把祝福说得既应景又不显得太书面
- 你善于把用户名字自然融入日常对话中，就像朋友间聊天一样
## 微信社交注意事项
- 避免过于正式的格式（如：尊敬的xxx、此致敬礼、恭祝）
- 不使用公文写作格式（如：顿首、敬启、谨启）
- 可以适当使用表情包和emoji增添活力
- 根据关系远近使用不同的称呼方式
- 保持对话的连续性，像平常聊天一样自然
- 字数要适中，不要太长（建议30-50字为宜）
## 主要功能
### 1. 回复拜年祝福
帮用户回复收到的祝福，做到：
- 分析对方的祝福内容和语气
- 看清发信人的身份（比如长辈、朋友、同事等）
- 根据情况给出合适的回复，自然不突兀
- 巧妙用上蛇年元素，增添年味儿
- 把用户名字自然融入（比如"小明在此恭祝..."）
### 2. 创作暖心祝福
帮用户写出暖心的拜年信息：
- 根据收信人的身份定制专属祝福
- 融入蛇年特色，让祝福更应景
- 根据场合调整表达方式
- 加入用户姓名，让祝福更有温度
## 蛇年特色祝福库
### 传统典故新解
🐍 巳巳如意（谐音：事事如意）
🐍 青蛇出洞（寓意：新的开始，充满活力）
🐍 金蛇狂舞（寓意：好运连连，喜事连连）
🐍 巳来运转（寓意：运势好转，前程似锦）
🐍 巳福呈祥（寓意：福气满满，吉祥如意）
### 创新祝福语
🎊 巳泽东来福满门（福气满满）
🎊 蛇舞新程展宏图（事业腾飞）
🎊 巳岁迎春百事兴（万事顺遂）
🎊 金巳纳福送吉祥（吉祥如意）
🎊 巳年福气进门来（福气临门）
## 使用方式
### 回复别人的祝福
只需告诉我：
- 谁发的祝福（身份关系）
- 具体说了啥（原始内容）
- 你的名字（用于个性化）
- 特别说明（如果有的话）
### 主动发祝福
告诉我这些就行：
- 要发给谁（对方身份）
- 什么场合（私聊还是群发）
- 你的名字（让祝福更有温度）
- 特别要求（如果有的话）
## 回复风格指南
### 微信祝福示例
1️⃣ 给长辈（亲切自然型）
"新年好呀～小明给您拜年啦！🧧 祝您蛇年身体倍儿棒，每天开开心心的！新的一年福气满满，开心到家！❤️"
2️⃣ 给朋友（轻松活泼型）
"新年好啊！🎊 是小明来啦～祝你蛇年好运连连，开心加倍！巳巳如意，美事撞满怀！😊"
3️⃣ 给同事（友好随性型）
"新年好！小明来拜年啦 🎈 祝你蛇年工作顺心，日子甜蜜，事事都巳巳如意！✨"
4️⃣ 群聊祝福（欢快热闹型）
"大家新年好呀！小明给大家拜年啦！🎊 祝各位蛇年大吉，福气满满！一起开开心心迎新春！🎈"
## 温馨提示
- 用户名要自然融入，不要生硬
- 根据关系调整措辞，亲疏有别
- 多用蛇年吉祥话，增添年味
- 保持喜庆祥和的氛围
- 不同场合要区分正式度
- 避免千篇一律，保持新意
快来试试吧！告诉我你想发/回复什么样的祝福，我来帮你写得暖暖的、喜气洋洋！🎊✨
```


值得注意的是，claude 如果不这样写 prompt，输出的结果那是真地不行；而至于 DeepSeek，加不加这样的 prompt，区别不是特别大，主要是会思考。

所以真地，诚不欺我：

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300835148.png)


原本昨天下午就已经写好了 DeepSeek 的适配，结果发现真正的瓶颈在于，OCR 的识别效果不好。

很多大模型虽然支持图片理解（比如 DeepSeek 会在图片里没有识别出文字时报错），但是只支持通用的 OCR，也就是只管提取出图片里的文字，不管位置、颜色等。

有朋友说，Gemini 效果更好，毕竟多模态，我也去试了试，结果也不行：

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300839089.png)

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300840798.png)

所以，最后，我让 AI 给我一套中文 OCR 解析方案，它给我指了条明路，参考： [百度在线网络技术(北京)有限公司（2000 年 10 月 19 日）](https://web.archive.org/web/20001019062953/http://www.baidu.com/)

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300846422.png)


Okay，所以我们在 Windsurf（AI 代码编辑器）、DeepSeek（最性价比 AI 推理模型）之外，就要用上第三个工具：百度 OCR：

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300849304.png)

它会生成带有 bbox 位置的结构化数据，为了方便校验，我又花了大概十分钟让 AI 写了个标注，再把结构化的文本数据丢给我们敬爱的 DeepSeek（其实 Claude 这里也行，毕竟不需要很强的推理，甚至直接用朴素的手写算法，按照坐标分类），就可以得到拼装好的聊天记录了。

做完了发了一个朋友圈，有朋友过来问，我觉得问地还挺有代表性的，所以也顺带分享一下，以防有其他人需要：

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300859979.png)


具体请看最后一章节。

## **03.** AI 时代开发的一些经验阶段性汇总
### 怎样才能高速开发一款软件

- 1.  先 clone 一个好用的脚手架或者模板（比如 #公众号：艾逗笔 200 刀的 ShipAny，质量和口碑都是很不错的）而非让 AI 从头开始写代码，因为有很多重复工作
- 2. 使用cursor 或者 Windsurf 等 AI IDE 进行主开发
- 3. 使用 JetBrains 等 IDE 辅助开发，比如 refactor 等场景，就更适合使用 JB 而非 VSCode 也非 AI，参考 【视频：devin】
- 4. 无论是基于 VSCode 的 Cursor、Windsurf 等还是 JetBrains，熟练掌握它们各个 language service 的 index 机制与操作是有必要的，比如有时候 AI 改完了代码，但是 IDE 还报错，是因为需要 reindex，这时候一般 `cmd+shift+p` 后 可以 reload 对应的 language service，否则需要重启 IDE，体验很不好

### AI IDE 的一些个人使用技巧

1. 要配置一些确实有用的 prompt：
	- 1. 让 AI 输出的代码尽量符合业界最佳实践（或者 AI 最佳实践，比如一个文件要短）
	- 2. 让 AI 能快速领悟整个项目的架构、技术栈
	- 3. 让 AI 能做一些预设置好的工作，比如同步/循环生成文档、测试之类
2. 尽量使用最好的推理模型（例如 O1-Pro、DS-R1 等）解决研究性、架构性问题，尽量使用最好的编程模型（例如 Claude-3.5-Sonnet）解决具体的实现问题
3. 目前的 AI Chat Panel 基本上都是一个 stack，但我们的任务往往是树状展开的（每个新任务要么是之前任务的子任务，要么是之前某一级的兄弟任务），因此假如你能通过 git 时刻维护代码的变动，同时善用 AI IDE 的时间窗回滚功能（windsurf 回滚时代码和聊天都回滚，cursor 额外支持代码不回滚的模式），你就可以在拥有在任何空间恣意穿梭的能力，你可以把你的头放心地交给 AI
4. 除了回滚之外，有时候即使明知道 AI 回复已经错误，我也会刻意让它输出，然后在合适的时候打断，这样会有一段错误的上下文，接着我再对它纠偏，这样它就能避免再犯这样的错误了

### LLM 开发的一些经验

1. 有时候利用低代码平台例如 Dify 把一个 LLM 调用封装成 API，再嵌入到程序里，还是挺有用的，例如：[分支大模型 - Dify](https://cloud.dify.ai/app/b95de0c5-15fc-4e08-9f42-260261b66a7e/workflow)。另一个细微的优点：在 Dify 中可以直接把文件当做变量，嵌入到 prompt 里，不用去研究各个 SDK 的结构是如何，这点挺有意思。我低代码用的不多，也在逐渐学习使用。
   
![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300742528.png)

2. 专业的 LLM 平台（例如 [Langfuse](https://langfuse.com/) 等）还有一些较为显著的优势，比如版本管理、可观测性等：

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300746809.png)


3. 访问国外的大模型需要梯子，所以 NextJS 的 Edge 函数（默认寻找最近的服务器）就几乎不可以跑在国内的服务器上，只能走后端，后端配置 proxy 也有多种讲究，首先是有 TUN 模式的，这样默认穿透；否则要在 SDK 中使用 `HttpsProxyAgent` 之类的配置；还有更极端的，Vercel 的 AI SDK 需要自定义 fetch 函数，参考：[httpAgent for experimental AI core provider packages · Issue #1360 · vercel/ai](https://github.com/vercel/ai/issues/1360)

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300754426.png)

4. python 生态有一个比较好的聚合各大 LLM 的库 LiteLLM，NodeJS 生态很可惜没有那么全的，例如 [Similar library to LiteLLM (a python library)? : r/node](https://www.reddit.com/r/node/comments/16wialr/similar_library_to_litellm_a_python_library/)，我们这个项目为了对比不同回复的效果，重点对比了 DeepSeek 和 Claude，最终用了 Vercel 的 AI SDK，因为它们有明确的 R1 文档： [Guides: Get started with DeepSeek R1](https://sdk.vercel.ai/docs/guides/r1)。基于它，我很快地实现了实时地流式推理输出。

### 后端开发的一些经验

1. 目前很多创业公司用的都是 FastAPI
2. 再配个 ApiFox 可以做很好看的 API 交付
3. 但我个人为了全栈的开发效率，很多时候还是优先使用 NodeJS
4. 依赖注入是一个很有意思的设计思想，Spring 与 NestJS 里大量使用，我个人也尝试在之前的 oh-my-commit 项目里大量使用了`typed` 
5. DeepSeek 刚被挖出来写了很多 CUDA 中间层的代码，并且被证明 AI 也是有能力写对汇编代码，基于此，我们应该多去学学 Rust，反正 AI 会就完事了，我们就做做测试工程师
### 前端开发的一些经验

1. 创业者 @PuppyAgent 非常推荐用 figma 可以直出设计稿，并且可继续修改，并生成代码
2. 也有一些软件可以直接基于目标图生成代码，这个功能其实目前的 claude 也能完成的不错，只不过还没到商业化那个级别，有不少的脏活累活，但也有一些创业者在做，包括爱逗笔~ 
3. 纯 web 推荐 NextJS，纯 pc 推荐 Electron，小程序的话推荐 UniApp，尽管个人更 prefer Taro
4. 有条件可以再配个屏，or 两个……

## **04.** DeepSeek：基于 OCR 数据还原聊天记录的推理全过程

> 因为涉及部分朋友隐私，已得到许可，但稍加处理，还请谅解！

![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300902643.png)
![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300903182.png)
![image.png](https://poketto.oss-cn-hangzhou.aliyuncs.com/202501300904120.png)
